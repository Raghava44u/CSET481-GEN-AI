{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4PE5DtCVUhY",
        "outputId": "63a81b5e-af1c-4234-dc28-7c6fbf1399e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E23CSEU2320\n",
            "LAB2\n"
          ]
        }
      ],
      "source": [
        "print(\"E23CSEU2320\")\n",
        "print(\"LAB2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "from collections import Counter\n",
        "\n",
        "dataset_choice = \"mnist\"\n",
        "epochs = 50\n",
        "batch_size = 128\n",
        "noise_dim = 100\n",
        "learning_rate = 0.0002\n",
        "save_interval = 5\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "os.makedirs(\"generated_samples\", exist_ok=True)\n",
        "os.makedirs(\"final_generated_images\", exist_ok=True)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])   # [-1, 1]\n",
        "])\n",
        "\n",
        "if dataset_choice == \"mnist\":\n",
        "    dataset = datasets.MNIST(\"./data\", train=True, transform=transform, download=True)\n",
        "else:\n",
        "    dataset = datasets.FashionMNIST(\"./data\", train=True, transform=transform, download=True)\n",
        "\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(noise_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 28*28),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.net(z)\n",
        "        return img.view(z.size(0), 1, 28, 28)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img = img.view(img.size(0), -1)\n",
        "        return self.net(img)\n",
        "\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(G.parameters(), lr=learning_rate)\n",
        "optimizer_D = optim.Adam(D.parameters(), lr=learning_rate)\n",
        "\n",
        "# train gan\n",
        "for epoch in range(1, epochs + 1):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for imgs, _ in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        batch = imgs.size(0)\n",
        "\n",
        "        real_labels = torch.ones(batch, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch, 1).to(device)\n",
        "\n",
        "        # ---- Train Discriminator ----\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        real_out = D(imgs)\n",
        "        real_loss = criterion(real_out, real_labels)\n",
        "\n",
        "        z = torch.randn(batch, noise_dim).to(device)\n",
        "        fake_imgs = G(z)\n",
        "        fake_out = D(fake_imgs.detach())\n",
        "        fake_loss = criterion(fake_out, fake_labels)\n",
        "\n",
        "        d_loss = real_loss + fake_loss\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Accuracy of discriminator\n",
        "        preds = torch.cat([real_out, fake_out])\n",
        "        labels = torch.cat([real_labels, fake_labels])\n",
        "        correct += (preds.round() == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # ---- Train Generator ----\n",
        "        optimizer_G.zero_grad()\n",
        "        g_loss = criterion(D(fake_imgs), real_labels)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "    d_acc = 100 * correct / total\n",
        "\n",
        "    print(f\"Epoch {epoch}/{epochs} | D_loss: {d_loss.item():.2f} | \"\n",
        "          f\"D_acc: {d_acc:.2f}% | G_loss: {g_loss.item():.2f}\")\n",
        "\n",
        "    if epoch % save_interval == 0:\n",
        "        save_image(fake_imgs[:25],\n",
        "                   f\"generated_samples/epoch_{epoch:02d}.png\",\n",
        "                   nrow=5, normalize=True)\n",
        "\n",
        "# final 100 images\n",
        "z = torch.randn(100, noise_dim).to(device)\n",
        "final_imgs = G(z)\n",
        "\n",
        "for i in range(100):\n",
        "    save_image(final_imgs[i],\n",
        "               f\"final_generated_images/img_{i+1}.png\",\n",
        "               normalize=True)\n",
        "\n",
        "# classifier\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "classifier = Classifier().to(device)\n",
        "optimizer_C = optim.Adam(classifier.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train classifier on REAL data\n",
        "for _ in range(5):\n",
        "    for imgs, labels in loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer_C.zero_grad()\n",
        "        outputs = classifier(imgs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer_C.step()\n",
        "\n",
        "# Evaluate generated images\n",
        "classifier.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = classifier(final_imgs)\n",
        "    preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "counts = Counter(preds.cpu().numpy())\n",
        "\n",
        "print(\"\\nLabel Distribution of Generated Images:\")\n",
        "for label, count in counts.items():\n",
        "    print(f\"Class {label}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNr6ux7hVbPZ",
        "outputId": "86109091-d571-4853-cefa-6a14dcc37a59"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.6MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 493kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.62MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 | D_loss: 0.12 | D_acc: 89.28% | G_loss: 5.78\n",
            "Epoch 2/50 | D_loss: 0.06 | D_acc: 98.69% | G_loss: 9.07\n",
            "Epoch 3/50 | D_loss: 0.08 | D_acc: 92.45% | G_loss: 5.39\n",
            "Epoch 4/50 | D_loss: 0.77 | D_acc: 82.74% | G_loss: 2.76\n",
            "Epoch 5/50 | D_loss: 0.53 | D_acc: 79.32% | G_loss: 2.05\n",
            "Epoch 6/50 | D_loss: 0.52 | D_acc: 76.52% | G_loss: 3.83\n",
            "Epoch 7/50 | D_loss: 0.54 | D_acc: 83.20% | G_loss: 2.41\n",
            "Epoch 8/50 | D_loss: 0.82 | D_acc: 85.40% | G_loss: 1.62\n",
            "Epoch 9/50 | D_loss: 0.68 | D_acc: 82.27% | G_loss: 2.23\n",
            "Epoch 10/50 | D_loss: 2.26 | D_acc: 85.12% | G_loss: 1.56\n",
            "Epoch 11/50 | D_loss: 0.59 | D_acc: 82.64% | G_loss: 2.06\n",
            "Epoch 12/50 | D_loss: 0.44 | D_acc: 78.25% | G_loss: 2.44\n",
            "Epoch 13/50 | D_loss: 0.69 | D_acc: 82.31% | G_loss: 2.52\n",
            "Epoch 14/50 | D_loss: 0.58 | D_acc: 86.61% | G_loss: 2.34\n",
            "Epoch 15/50 | D_loss: 0.28 | D_acc: 90.00% | G_loss: 3.23\n",
            "Epoch 16/50 | D_loss: 0.46 | D_acc: 92.47% | G_loss: 4.60\n",
            "Epoch 17/50 | D_loss: 0.56 | D_acc: 89.68% | G_loss: 3.17\n",
            "Epoch 18/50 | D_loss: 0.28 | D_acc: 90.60% | G_loss: 3.90\n",
            "Epoch 19/50 | D_loss: 1.20 | D_acc: 90.53% | G_loss: 2.66\n",
            "Epoch 20/50 | D_loss: 0.49 | D_acc: 94.78% | G_loss: 9.31\n",
            "Epoch 21/50 | D_loss: 0.49 | D_acc: 92.20% | G_loss: 7.49\n",
            "Epoch 22/50 | D_loss: 0.17 | D_acc: 96.47% | G_loss: 6.62\n",
            "Epoch 23/50 | D_loss: 0.20 | D_acc: 96.35% | G_loss: 3.84\n",
            "Epoch 24/50 | D_loss: 0.77 | D_acc: 94.72% | G_loss: 4.71\n",
            "Epoch 25/50 | D_loss: 0.11 | D_acc: 91.56% | G_loss: 6.49\n",
            "Epoch 26/50 | D_loss: 0.10 | D_acc: 96.92% | G_loss: 5.48\n",
            "Epoch 27/50 | D_loss: 0.09 | D_acc: 98.76% | G_loss: 10.35\n",
            "Epoch 28/50 | D_loss: 0.27 | D_acc: 97.73% | G_loss: 7.51\n",
            "Epoch 29/50 | D_loss: 0.11 | D_acc: 97.69% | G_loss: 5.89\n",
            "Epoch 30/50 | D_loss: 0.22 | D_acc: 95.08% | G_loss: 5.61\n",
            "Epoch 31/50 | D_loss: 0.43 | D_acc: 95.40% | G_loss: 4.38\n",
            "Epoch 32/50 | D_loss: 0.32 | D_acc: 94.02% | G_loss: 5.16\n",
            "Epoch 33/50 | D_loss: 0.16 | D_acc: 94.56% | G_loss: 6.68\n",
            "Epoch 34/50 | D_loss: 0.30 | D_acc: 95.18% | G_loss: 3.92\n",
            "Epoch 35/50 | D_loss: 0.35 | D_acc: 92.51% | G_loss: 5.60\n",
            "Epoch 36/50 | D_loss: 0.63 | D_acc: 92.73% | G_loss: 3.67\n",
            "Epoch 37/50 | D_loss: 0.45 | D_acc: 92.58% | G_loss: 4.00\n",
            "Epoch 38/50 | D_loss: 0.34 | D_acc: 92.41% | G_loss: 4.28\n",
            "Epoch 39/50 | D_loss: 0.37 | D_acc: 94.09% | G_loss: 4.08\n",
            "Epoch 40/50 | D_loss: 0.42 | D_acc: 94.62% | G_loss: 3.81\n",
            "Epoch 41/50 | D_loss: 0.35 | D_acc: 93.21% | G_loss: 4.40\n",
            "Epoch 42/50 | D_loss: 0.44 | D_acc: 92.08% | G_loss: 4.15\n",
            "Epoch 43/50 | D_loss: 0.57 | D_acc: 91.89% | G_loss: 3.42\n",
            "Epoch 44/50 | D_loss: 0.52 | D_acc: 89.90% | G_loss: 5.26\n",
            "Epoch 45/50 | D_loss: 0.55 | D_acc: 91.84% | G_loss: 4.38\n",
            "Epoch 46/50 | D_loss: 0.67 | D_acc: 92.43% | G_loss: 2.94\n",
            "Epoch 47/50 | D_loss: 0.40 | D_acc: 91.43% | G_loss: 3.93\n",
            "Epoch 48/50 | D_loss: 0.59 | D_acc: 92.22% | G_loss: 3.97\n",
            "Epoch 49/50 | D_loss: 0.66 | D_acc: 90.69% | G_loss: 3.17\n",
            "Epoch 50/50 | D_loss: 0.57 | D_acc: 91.13% | G_loss: 3.06\n",
            "\n",
            "Label Distribution of Generated Images:\n",
            "Class 6: 10\n",
            "Class 3: 29\n",
            "Class 1: 22\n",
            "Class 5: 13\n",
            "Class 9: 6\n",
            "Class 0: 3\n",
            "Class 2: 6\n",
            "Class 4: 7\n",
            "Class 8: 3\n",
            "Class 7: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Z98DyBIVj-_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}